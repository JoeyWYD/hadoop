mapreduce优化：
优化一：设置map的数量：调整inputspalit的大小，来调整map任务数量。参数： set mapred.max.split.size=
优化二：如果公司磁盘空间比较富余，可以适当增加副本数，来增加map任务的本地化，减少网络拉取数据的时间，提高效率。
优化三：可以启用将reduce聚合操作前置到map端，也就是合并，也叫combine操作。
优化四：可以使用mapjoin. 适用场景：一张大表，一张小表，小表可以放入内存。
原理就是将小表加载到内存里，进行在map端进行join，可以减少shuffer过程，提高效率
减少reduce阶段拉取map端数据的网络io，提高效率。
方法：将redcue需要执行的程序，移到map端进行执行。
reduce接收的数据类型和map输出的保持一致。combine端接收的数据是map端输出的数据。
当一个任务长时间阻塞，卡住，需要杀死：hadoop job -kill job_1550850865802_0006。
使用mapreduce程序可以对数据进行清洗，过滤，筛选，回填等操作，实际大部分操作是发生在map阶段。
好处：可以将不必要参加计算的数据过滤，减少计算量。